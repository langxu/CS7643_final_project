{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dimension Reduction Model\n",
    "\n",
    "*** Note\n",
    "1. Some of the torch version do not support \"Weights=None\". Instead, we change it to \"pretrain = False\" to support majority of the torch"
   ],
   "id": "51077af46f715da4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:54:01.687773Z",
     "start_time": "2025-04-27T19:53:55.648384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Allow auto-reloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# Fix for library conflicts\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# Project-specific imports\n",
    "from Dimension_Reduction_Model.predict import load_trained_model, predict_image_class\n",
    "from Dimension_Reduction_Model.data_preparation import get_cifar10_datasets, get_dataloader\n"
   ],
   "id": "8f22e8bb1fe33a49",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:54:09.923882Z",
     "start_time": "2025-04-27T19:54:09.718444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Check CUDA availability\n",
    "'''\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Current device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "6be156084c767547",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Current device name: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:54:11.952138Z",
     "start_time": "2025-04-27T19:54:11.442761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Load the dimension reduction model with the pre-trained PTH\n",
    "'''\n",
    "model = load_trained_model('./Dimension_Reduction_Model/output/resnet18_4cls_64dim_1tm_model.pth', 'resnet18', 64, 4, device)"
   ],
   "id": "7df9e5fedfbb02cf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\envs\\final_virtual\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\final_virtual\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from ./Dimension_Reduction_Model/output/resnet18_4cls_64dim_1tm_model.pth\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:54:15.567315Z",
     "start_time": "2025-04-27T19:54:13.375368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Load the data\n",
    "'''\n",
    "train_dataset, test_dataset = get_cifar10_datasets(data_dir='./Dimension_Reduction_Model/data')\n",
    "train_loader, test_loader = get_dataloader(train_dataset, test_dataset, batch_size=64, num_workers=8)"
   ],
   "id": "cc44fb29f10a09c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering and remapping base training dataset...\n",
      "Dataset filtered. New number of samples: 20000\n",
      "Filtering and remapping base testing dataset...\n",
      "Dataset filtered. New number of samples: 4000\n",
      "Triplet Dataset created with 20000 samples (based on base dataset size).\n",
      "Classes found in dataset: [0, 1, 2, 3]\n",
      "Filtered CIFAR-10 Triplet train loader and standard test loader created with 8 workers.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:54:15.754954Z",
     "start_time": "2025-04-27T19:54:15.578810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "test data and its label, and show the mapping of the labeling of these 4 classes\n",
    "'''\n",
    "NEW_CLASS_MAPPING = {\n",
    "    3: 0, # cat -> 0\n",
    "    5: 1, # dog -> 1\n",
    "    8: 2, # ship -> 2\n",
    "    9: 3  # truck -> 3\n",
    "}\n",
    "\n",
    "N, H, W, C = test_dataset.data.shape\n",
    "print(f\"(In test data) Number of images: {N}, Height: {H}, Width: {W}, Channel: {C}\")"
   ],
   "id": "a6bc886d97730647",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(In test data) Number of images: 4000, Height: 32, Width: 32, Channel: 3\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:54:56.232029Z",
     "start_time": "2025-04-27T19:54:15.897533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Split data into ab_images/cd_images, and ab_labels/cd_labels\n",
    "'''\n",
    "ab_images, cd_images = [], []\n",
    "ab_labels, cd_labels = [], []\n",
    "# this flag the number of image off miss assign from the contrastive learning\n",
    "ab_incorrect, cd_incorrect = 0,0\n",
    "# denormalize the image back to its original vector\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    pred_label, prob, _= predict_image_class(model, image, device, True)\n",
    "    # denormalize the image, and put the image shape back to [3, 32, 32]\n",
    "    denom_image = (image * torch.tensor(CIFAR10_STD ).view(1, 3, 1, 1) + torch.tensor(CIFAR10_MEAN ).view(1, 3, 1, 1)).squeeze(0).to(device)\n",
    "\n",
    "    if pred_label in [\"cat\",\"dog\"]:\n",
    "        if label not in [0,1]:\n",
    "            ab_incorrect += 1\n",
    "        else:\n",
    "            ab_images.append(denom_image)\n",
    "            label = torch.tensor(label).long().to(device)\n",
    "            ab_labels.append(label)\n",
    "    elif pred_label in [\"ship\",\"truck\"]:\n",
    "        if label not in [2,3]:\n",
    "            cd_incorrect += 1\n",
    "        else:\n",
    "            cd_images.append(denom_image)\n",
    "            # all fix-match model only takes 0 or 1 as labels\n",
    "            label = torch.tensor(label-2).long().to(device)\n",
    "            cd_labels.append(label)"
   ],
   "id": "2cf4d9c15cc8ebb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:54:56.466734Z",
     "start_time": "2025-04-27T19:54:56.239632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Manager model output (based on the animal/vehicle category)\n",
    "'''\n",
    "print(f\"Number of correct animal prediction: {len(ab_images)}\")\n",
    "print(f\"Number of incorrect animal prediction: {ab_incorrect}\")\n",
    "print(f\"Accuracy of correct animal prediction: {len(ab_images)/((len(ab_images) + cd_incorrect))}\")\n",
    "print(\"______________________________________________________________________________________________\")\n",
    "print(f\"Number of correct vehicle prediction: {len(cd_images)}\")\n",
    "print(f\"Number of incorrect vehicle prediction: {cd_incorrect}\")\n",
    "print(f\"Accuracy of correct animal prediction: {len(cd_images)/((len(cd_images) + ab_incorrect))}\")"
   ],
   "id": "722eb22c662d182",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct animal prediction: 1966\n",
      "Number of incorrect animal prediction: 49\n",
      "Accuracy of correct animal prediction: 0.983\n",
      "______________________________________________________________________________________________\n",
      "Number of correct vehicle prediction: 1951\n",
      "Number of incorrect vehicle prediction: 34\n",
      "Accuracy of correct animal prediction: 0.9755\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:54:56.984687Z",
     "start_time": "2025-04-27T19:54:56.782206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Double check the shape of each image (to make sure we fed the correct data to the Fix Match Model)\n",
    "'''\n",
    "denom_image.shape"
   ],
   "id": "3c5ec12ddc3c90f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fix Match Model\n",
    "\n",
    "*** Note\n",
    "1. There are two fix match models we used for cat/dog and ship/truck classification"
   ],
   "id": "92baf4e7a4c2f2d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:54:57.311739Z",
     "start_time": "2025-04-27T19:54:57.095748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Constants (must match training)\n",
    "CIFAR10_CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "SELECTED_CLASSES = [0, 1] # the code itself does not matter, just need to make sure the index 0 is cat/ship, 1 is dog/truck\n",
    "#SELECTED_CLASSES = ['ship', 'truck']\n",
    "NUM_CLASSES = len(SELECTED_CLASSES)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, depth=28, widen_factor=2, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        n_channels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
    "        assert (depth - 4) % 6 == 0\n",
    "        n = (depth - 4) // 6\n",
    "        self.conv1 = nn.Conv2d(3, n_channels[0], kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.block1 = self._make_block(n, n_channels[0], n_channels[1], 1, dropout_rate, True)\n",
    "        self.block2 = self._make_block(n, n_channels[1], n_channels[2], 2, dropout_rate)\n",
    "        self.block3 = self._make_block(n, n_channels[2], n_channels[3], 2, dropout_rate)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels[3], momentum=0.001)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(n_channels[3], num_classes)\n",
    "\n",
    "    def _make_block(self, n, in_planes, out_planes, stride, dropout_rate=0.0, activate_before_residual=False):\n",
    "        layers = []\n",
    "        for i in range(int(n)):\n",
    "            layers.append(BasicBlock(i == 0 and in_planes or out_planes,\n",
    "                                     out_planes,\n",
    "                                     i == 0 and stride or 1,\n",
    "                                     dropout_rate,\n",
    "                                     activate_before_residual))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropout_rate=0.0, activate_before_residual=False):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes, momentum=0.001)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes, momentum=0.001)\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(\n",
    "            in_planes, out_planes, kernel_size=1, stride=stride, padding=0, bias=True) or None\n",
    "        self.activate_before_residual = activate_before_residual\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut and self.activate_before_residual:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.bn1(x)\n",
    "            out = self.relu1(out)\n",
    "        out = self.conv1(out if self.equalInOut else x)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        if self.dropout_rate > 0:\n",
    "            out = F.dropout(out, p=self.dropout_rate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        shortcut = x if self.equalInOut else self.convShortcut(x)\n",
    "        return torch.add(out, shortcut)\n",
    "\n",
    "def evaluate(model, eval_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in eval_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    per_class_accuracy = []\n",
    "    for i, class_name in enumerate(SELECTED_CLASSES):\n",
    "        correct_class = sum((np.array(all_targets) == i) & (np.array(all_preds) == i))\n",
    "        total_class = sum(np.array(all_targets) == i)\n",
    "        accuracy = 100. * correct_class / total_class if total_class > 0 else 0.0\n",
    "        per_class_accuracy.append(accuracy)\n",
    "\n",
    "    return total_loss / total, 100. * correct / total, per_class_accuracy\n",
    "\n",
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "# remvoe the toTensor part since the manager stage is passing the tensor version to the fix match model\n",
    "def get_normalizer():\n",
    "    return transforms.Compose([\n",
    "        transforms.Normalize(**NORMALIZATION_VARIABLES)\n",
    "    ])"
   ],
   "id": "6a18ac2f73372c0f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:54:57.515811Z",
     "start_time": "2025-04-27T19:54:57.317222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The normalize verctors for fix match model\n",
    "NORMALIZATION_VARIABLES = {\n",
    "    \"mean\": (0.4914, 0.4822, 0.4465),\n",
    "    \"std\": (0.2470, 0.2435, 0.2616)\n",
    "}\n",
    "\n",
    "transform = get_normalizer()\n",
    "\n",
    "ab_dataset = TensorDataset(ab_images, ab_labels, transform=transform)\n",
    "ab_loader = DataLoader(ab_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "cd_dataset = TensorDataset(cd_images, cd_labels, transform=transform)\n",
    "cd_loader = DataLoader(cd_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ],
   "id": "388150527125879f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:55:00.202180Z",
     "start_time": "2025-04-27T19:54:57.625295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ab_model = WideResNet(num_classes=2).to(device)\n",
    "ab_model.load_state_dict(torch.load('Fix_Match_Model/best_model_ema.pth', map_location=device))\n",
    "\n",
    "ab_loss, ab_acc, ab_per_class_acc = evaluate(ab_model, ab_loader, device)\n",
    "\n",
    "cd_model = WideResNet(num_classes=2).to(device)\n",
    "cd_model.load_state_dict(torch.load('Fix_Match_Model/best_model_ema_shipTruckFL.pth', map_location=device))\n",
    "\n",
    "cd_loss, cd_acc, cd_per_class_acc = evaluate(cd_model, cd_loader, device)\n",
    "\n",
    "# for the final accuracy calculation, we need to find the correct prediction/total iamges, which incluidng miss classified imaged from contrastive model\n",
    "ab_size = len(ab_loader.dataset)\n",
    "cd_size = len(cd_loader.dataset)\n",
    "final_acc = (ab_acc * ab_size + cd_acc * cd_size)/(ab_size + cd_size + ab_incorrect + cd_incorrect)\n",
    "\n",
    "print(\"Final accuracy: {:.2f}%\".format(final_acc))"
   ],
   "id": "36844a6d36356b18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 79.65%\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:55:00.452357Z",
     "start_time": "2025-04-27T19:55:00.297017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ab_size = len(ab_loader.dataset)\n",
    "cd_size = len(cd_loader.dataset)\n",
    "final_acc = (ab_acc * ab_size + cd_acc * cd_size)/(ab_size + cd_size + ab_incorrect + cd_incorrect)\n",
    "final_acc2 = (ab_acc * ab_size + cd_acc * cd_size)/(ab_size + cd_size)\n",
    "print(\"Final accuracy (consider miss classification error from CL): {:.2f}%\".format(final_acc))\n",
    "print(\"Final accuracy2 (not consider classification error from CL): {:.2f}%\".format(final_acc2))"
   ],
   "id": "31f7440b343a8b42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy (consider miss classification error from CL): 79.65%\n",
      "Final accuracy2 (not consider classification error from CL): 81.34%\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:55:00.717382Z",
     "start_time": "2025-04-27T19:55:00.546387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "The cat/dog specialist accuracy (consider CL error)\n",
    "'''\n",
    "(ab_acc * ab_size )/(ab_size + ab_incorrect)"
   ],
   "id": "6e90dd149342648e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.4789081885856"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T19:55:00.979818Z",
     "start_time": "2025-04-27T19:55:00.796085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "The ship/truck specialist accuracy (consider CL error)\n",
    "'''\n",
    "(cd_acc * cd_size)/(cd_size + cd_incorrect)"
   ],
   "id": "7d7fff438a599170",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.97481108312343"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "18b2bd83a1af335f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

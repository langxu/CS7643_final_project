{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c950d9-91fa-45c4-a64b-ef2dc95150de",
   "metadata": {},
   "source": "## Overall Model evaluation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T19:27:35.652276Z",
     "start_time": "2025-04-24T19:27:32.352991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ],
   "id": "c8d1737dfb92cfd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from Tianyi_Model.predict import load_trained_model, predict_image_class\n",
    "from Tianyi_Model.data_preparation import get_cifar10_datasets, get_dataloader\n",
    "from Tianyi_Model.train import train_model"
   ],
   "id": "46c35c60a127621c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "350a556354dfee4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T23:48:02.915878Z",
     "start_time": "2025-04-23T23:48:02.872825Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 8,
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Constants (must match training)\n",
    "CIFAR10_CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "SELECTED_CLASSES = ['cat', 'dog']\n",
    "NUM_CLASSES = len(SELECTED_CLASSES)\n",
    "BATCH_SIZE = 64\n",
    "NORMALIZATION_VARIABLES = {\n",
    "    \"mean\": (0.4914, 0.4822, 0.4465),\n",
    "    \"std\": (0.2470, 0.2435, 0.2616)\n",
    "}\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, depth=28, widen_factor=2, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        n_channels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
    "        assert (depth - 4) % 6 == 0\n",
    "        n = (depth - 4) // 6\n",
    "        self.conv1 = nn.Conv2d(3, n_channels[0], kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.block1 = self._make_block(n, n_channels[0], n_channels[1], 1, dropout_rate, True)\n",
    "        self.block2 = self._make_block(n, n_channels[1], n_channels[2], 2, dropout_rate)\n",
    "        self.block3 = self._make_block(n, n_channels[2], n_channels[3], 2, dropout_rate)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels[3], momentum=0.001)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(n_channels[3], num_classes)\n",
    "\n",
    "    def _make_block(self, n, in_planes, out_planes, stride, dropout_rate=0.0, activate_before_residual=False):\n",
    "        layers = []\n",
    "        for i in range(int(n)):\n",
    "            layers.append(BasicBlock(i == 0 and in_planes or out_planes,\n",
    "                                     out_planes,\n",
    "                                     i == 0 and stride or 1,\n",
    "                                     dropout_rate,\n",
    "                                     activate_before_residual))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropout_rate=0.0, activate_before_residual=False):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes, momentum=0.001)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes, momentum=0.001)\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(\n",
    "            in_planes, out_planes, kernel_size=1, stride=stride, padding=0, bias=True) or None\n",
    "        self.activate_before_residual = activate_before_residual\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut and self.activate_before_residual:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.bn1(x)\n",
    "            out = self.relu1(out)\n",
    "        out = self.conv1(out if self.equalInOut else x)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        if self.dropout_rate > 0:\n",
    "            out = F.dropout(out, p=self.dropout_rate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        shortcut = x if self.equalInOut else self.convShortcut(x)\n",
    "        return torch.add(out, shortcut)\n",
    "\n",
    "\n",
    "def get_normalizer():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**NORMALIZATION_VARIABLES)\n",
    "    ])\n",
    "\n",
    "def evaluate(model, eval_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in eval_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = F.cross_entropy(outputs, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    per_class_accuracy = []\n",
    "    for i, class_name in enumerate(SELECTED_CLASSES):\n",
    "        correct_class = sum((np.array(all_targets) == i) & (np.array(all_preds) == i))\n",
    "        total_class = sum(np.array(all_targets) == i)\n",
    "        accuracy = 100. * correct_class / total_class if total_class > 0 else 0.0\n",
    "        per_class_accuracy.append(accuracy)\n",
    "\n",
    "    return total_loss / total, 100. * correct / total, per_class_accuracy\n"
   ],
   "id": "1e05aa18-47c5-4e91-8d12-35cebd6d4123"
  },
  {
   "cell_type": "code",
   "id": "fb498191-7546-4560-95d2-2875dd4655f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T23:48:04.783616Z",
     "start_time": "2025-04-23T23:48:04.706103Z"
    }
   },
   "source": [
    "'''\n",
    "Suppose this is what the upward pass to the fix match part\n",
    "\n",
    "Will currently using the local dataset as a tempraray work\n",
    "'''\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# CIFAR-10 类别\n",
    "CIFAR10_CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "AB_CLASSES = ['cat', 'dog']\n",
    "CD_CLASSES = ['ship', 'truck']\n",
    "\n",
    "# 本地路径\n",
    "data_dir = r\"C:\\Users\\micha\\OneDrive\\Desktop\\Georgia Institute of Technology\\Spring 2025\\CS7643\\Final_Project\\Data\\cifar-10-batches-py\"\n",
    "test_batch_path = os.path.join(data_dir, \"test_batch\")\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        return pickle.load(fo, encoding='bytes')\n",
    "\n",
    "\n",
    "# 加载 test_batch\n",
    "batch = unpickle(test_batch_path)\n",
    "data = batch[b'data']  # shape: (10000, 3072)\n",
    "labels = batch[b'labels']\n",
    "\n",
    "# 转换成图像格式 (N, 32, 32, 3)\n",
    "data = data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# 分组函数\n",
    "def split_by_classes(target_classes):\n",
    "    target_indices = [CIFAR10_CLASSES.index(c) for c in target_classes]\n",
    "    mask = np.isin(labels, target_indices)\n",
    "    selected_images = data[mask]\n",
    "    selected_labels = labels[mask]\n",
    "    label_map = {CIFAR10_CLASSES.index(c): i for i, c in enumerate(target_classes)}\n",
    "    mapped_labels = [label_map[l] for l in selected_labels]\n",
    "    return list(selected_images), mapped_labels\n",
    "\n",
    "# 猫/狗组 默认输入是个tensor\n",
    "ab_images, ab_labels = split_by_classes(AB_CLASSES)\n",
    "\n",
    "# 船/卡车组 默认输入是个tensor\n",
    "cd_images, cd_labels = split_by_classes(CD_CLASSES)\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "53d80d7c-a977-475b-a991-731cd2558d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T23:48:05.371625Z",
     "start_time": "2025-04-23T23:48:05.358726Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images  # list of np.array (H, W, C)\n",
    "        self.labels = labels  # list of integers\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 转成 PIL.Image 然后应用 transform\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "42f7f509-4515-4e77-b728-f203821576b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T23:48:05.931510Z",
     "start_time": "2025-04-23T23:48:05.917572Z"
    }
   },
   "source": [
    "def get_normalizer():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**NORMALIZATION_VARIABLES)\n",
    "    ])\n",
    "\n",
    "NORMALIZATION_VARIABLES = {\n",
    "    \"mean\": (0.4914, 0.4822, 0.4465),\n",
    "    \"std\": (0.2470, 0.2435, 0.2616)\n",
    "}\n",
    "transform = get_normalizer()  \n",
    "\n",
    "ab_dataset = NumpyDataset(ab_images, ab_labels, transform=transform)\n",
    "ab_loader = DataLoader(ab_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "cd_dataset = NumpyDataset(cd_images, cd_labels, transform=transform)\n",
    "cd_loader = DataLoader(cd_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "38c34539-dd7b-42ca-8701-ee830b7ba16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T23:48:07.209873Z",
     "start_time": "2025-04-23T23:48:07.090537Z"
    }
   },
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ab_model = WideResNet(num_classes=2).to(device)\n",
    "ab_model.load_state_dict(torch.load('best_model_ema.pth', map_location=device))\n",
    "\n",
    "cd_model = WideResNet(num_classes=2).to(device)\n",
    "cd_model.load_state_dict(torch.load('best_model_ema_shipTruckFL.pth', map_location=device))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T23:57:04.961444Z",
     "start_time": "2025-04-23T23:56:45.891870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 假设 ab_loader 和 cd_loader 的长度分别是 AB 数据集和 CD 数据集的样本数量\n",
    "ab_size = len(ab_loader.dataset)\n",
    "cd_size = len(cd_loader.dataset)\n",
    "\n",
    "# 获取两个模型的准确率\n",
    "ab_loss, ab_acc, ab_per_class_acc = evaluate(ab_model, ab_loader, device)\n",
    "cd_loss, cd_acc, cd_per_class_acc = evaluate(cd_model, cd_loader, device)\n",
    "\n",
    "# 计算加权平均准确率\n",
    "total_samples = ab_size + cd_size\n",
    "overall_acc = (ab_acc * ab_size + cd_acc * cd_size) / total_samples\n",
    "\n",
    "print(\"整体准确率 (加权平均): {:.2f}%\".format(overall_acc))"
   ],
   "id": "5c320c472339d75e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整体准确率 (加权平均): 81.17%\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T00:10:18.352350Z",
     "start_time": "2025-04-24T00:10:18.330317Z"
    }
   },
   "cell_type": "code",
   "source": "print(ab_acc, cd_acc)",
   "id": "60a5473fd5bee1ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.1 91.25\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
